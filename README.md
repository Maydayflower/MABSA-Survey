# MABSA-Survey


## 1. MABSA
 
### 1.1 Multimodal Aspect Term Extraction(MATE)/Multimodal Named Entity Recognition(MNER)
1. Xinyu Wang, Jiong Cai, Yong Jiang, Pengjun Xie, Kewei Tu and Wei Lu. **Named Entity and Relation Extraction with Multi-Modal Retrieval**. EMNLP 2022 Findings
1. Baohang Zhou, Ying Zhang, Kehui Song, Wenya Guo, Guoqing Zhao, hongbin wang and Xiaojie Yuan. **A Span-based Multimodal Variational Autoencoder for Semi-supervised Multimodal Named Entity Recognition**. EMNLP 2022 [[code]](https://github.com/ZovanZhou/SMVAE)
1. Gang Zhao, Guanting Dong, Yidong Shi, Haolong Yan, Weiran Xu and Si Li. **Entity-level Interaction via Heterogeneous Graph for Multimodal Named Entity Recognition**. EMNLP 2022 Findings 
2. Jie Wang, Yan Yang, Keyu Liu, Zhiping Zhu and Xiaorong Liu. **M3S: Scene graph driven Multi-granularity Multi-task learning for Multi-modal NER**. TASLP 2022 [[paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9944151)
3. Xuwu Wang; Jiabo Ye; Zhixu Li; Junfeng Tian; Yong Jiang; Ming Yan; Ji Zhang; Yanghua Xiao. **CAT-MNER: Multimodal Named Entity Recognition with Knowledge-Refined Cross-Modal Attention**. ICME 2022 [[paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9859972)
4. Junyu Lu, Dixiang Zhang, Jiaxing Zhang, Pingjian Zhang. **Flat Multi-modal Interaction Transformer for Named Entity Recognition**. COLING 2022 [[paper]](https://aclanthology.org/2022.coling-1.179.pdf)
5. Bo Xu, Shizhou Huang, Ming Du, Hongya Wang, Hui Song. **Different Data, Different Modalities! Reinforced Data Splitting for Effective Multimodal Information Extraction from Social Media Posts**. COLING 2022 [[paper]](https://aclanthology.org/2022.coling-1.160.pdf)
6.  Meihuizi Jia, Xin Shen, Lei Shen, Jinhui Pang, Lejian Liao, Yang Song, Meng Chen, Xiaodong He. **Query Prior Matters: A MRC Framework for Multimodal Named Entity Recognition**. ACM MM 2022 [[paper]](https://dl.acm.org/doi/pdf/10.1145/3503161.3548427)
7.  Fei Zhao, Chunhui Li, Zhen Wu, Shangyu Xing, Xinyu Dai. **Learning from Different text-image Pairs: A Relation-enhanced Graph Convolutional Network for Multimodal NER**. ACM MM 2022 [[paper]](https://dl.acm.org/doi/pdf/10.1145/3503161.3548228)
1. Xiang Chen, Ningyu Zhang, Lei Li, Shumin Deng, Chuanqi Tan, Changliang Xu, Fei Huang, Luo Si, and Huajun Chen. **Hybrid Transformer with Multi-level Fusion for Multimodal Knowledge Graph Completion**. SIGIR 2022. [[paper]](https://arxiv.org/pdf/2205.02357.pdf) [[code]](https://github.com/zjunlp/MKGformer)
2. Xinyu Wang, Min Gui, Yong Jiang, Zixia Jia, Nguyen Bach, Tao Wang, Zhongqiang Huang, Fei Huang, and Kewei Tu. **ITA: Image-Text Alignments for Multi-Modal Named Entity Recognition**. NAACL 2022. [[paper]](https://arxiv.org/pdf/2112.06482.pdf) [[code]](https://github.com/Alibaba-NLP/KB-NER/tree/main/ITA)
3. Xiang Chen, Ningyu Zhang, Lei Li, Shumin Deng, Chuanqi Tan, Changliang Xu, Fei Huang, Luo Si, and Huajun Chen. **Good Visual Guidance Makes A Better Extractor: Hierarchical Visual Prefix for Multimodal Entity and Relation Extraction**. NAACL 2022 Findings. [[paper]](https://arxiv.org/pdf/2205.03521.pdf) [[code]](https://github.com/zjunlp/HVPNeT)
4. Bo Xu, Shizhou Huang, Chaofeng Sha, and Hongya Wang. **MAF: A General Matching and Alignment Framework for Multimodal Named Entity Recognition**. WSDM 2022. [[paper]](https://dl.acm.org/doi/pdf/10.1145/3488560.3498475?casa_token=mgnoLxqNY6sAAAAA:V6QKO_hH7_RkHeeDThokhq6vgRFdRqdepH9ZTPt5Ft1T9Qmj-KK4HPkoWI0TDn1I4nf-K15EaScVOg)
5. Dong Zhang, Suzhong Wei, Shoushan Li, Hanqian Wu, Qiaoming Zhu, and Guodong Zhou. **Multi-modal Graph Fusion for Named Entity Recognition with Targeted Visual Guidance**. AAAI 2021. [[paper]](https://www.aaai.org/AAAI21Papers/AAAI-2753.ZhangD.pdf) [[code]](https://github.com/TransformersWsz/UMGF)
6. Lin Sun, Jiquan Wang, Kai Zhang, Yindu Su and Fangsheng Weng. **RpBERT: A Text-image Relation Propagation-based BERT Model for Multimodal NER**. AAAI 2021. [[paper]](https://www.aaai.org/AAAI21Papers/AAAI-761.SunL.pdf) [[code]](https://github.com/Multimodal-NER/RpBERT)
7. Dawei Chen, Zhixu Li, Binbin Gu, and Zhigang Chen. **Multimodal Named Entity Recognition with Image Attributes and Image Knowledge**. DASFAA 2021. [[paper]](https://link.springer.com/content/pdf/10.1007%2F978-3-030-73197-7_12.pdf)
8. Shuguang Chen, Gustavo Aguilar, Leonardo Neves and Thamar Solorio. **Can images help recognize entities? A study of the role of images for Multimodal NER**. WNUT 2021. [[paper]](https://aclanthology.org/2021.wnut-1.11.pdf)
9. Luping Liu, Meiling Wang, Mozhi Zhang, Linbo Qing and Xiaohai He. **UAMNer: uncertainty-aware multimodal named entity recognition in social media posts**. Applied Intelligence 2021. [[paper]](https://link.springer.com/content/pdf/10.1007/s10489-021-02546-5.pdf)
10. Zhiwei Wu, Changmeng Zheng, Yi Cai, Junying Chen, Ho-fung Leung and Qing Li. **Multimodal Representation with Embedded Visual Guiding Objects for Named Entity Recognition in Social Media Posts**. ACM MM 2020. [[paper]](https://dl.acm.org/doi/pdf/10.1145/3394171.3413650)
11. Changmeng Zheng, Zhiwei Wu, Tao Wang, Yi Cai and Qing Li. **Object-Aware Multimodal Named Entity Recognition in Social Media Posts With Adversarial Learning**. IEEE Transactions on Multimedia 2020. [[paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9154571)
12. Jianfei Yu, Jing Jiang, Li Yang, and Rui Xia. **Improving Multimodal Named Entity Recognition via Entity Span Detection with Unified Multimodal Transformer**. ACL 2020. [[paper]](https://aclanthology.org/2020.acl-main.306.pdf) [[code]](https://github.com/jefferyYu/UMT)
13. Hanqian Wu, Siliang Cheng, Jingjing Wang, Shoushan Li, and Lian Chi. **Multimodal Aspect Extraction with Region-Aware Alignment Network**. NLPCC 2020. [[paper]](https://www.springerprofessional.de/en/multimodal-aspect-extraction-with-region-aware-alignment-network/18449698)
14. Di Lu, Leonardo Neves, Vitor Carvalho, Ning Zhang and Heng Ji. **Visual Attention Model for Name Tagging in Multimodal Social Media**. ACL 2018. [[paper]](https://aclanthology.org/P18-1185.pdf)
15. Qi Zhang, Jinlan Fu, Xiaoyu Liu and Xuanjing Huang. **Adaptive Co-Attention Network for Named Entity Recognition in Tweets**. AAAI 2018. [[paper]](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16432/16127)
16. Seungwhan Moon, Leonardo Neves and Vitor Carvalho. **Multimodal Named Entity Recognition for Short Social Media Posts**. NAACL 2018. [[paper]](https://aclanthology.org/N18-1078.pdf)


### 1.2 Multimodal Category based Sentiment Classification(MCBSC)
1. Jianfei Yu, Kai Chen, and Rui Xia. **Hierarchical Interactive Multimodal Transformer for Aspect-Based Multimodal Sentiment Analysis**. IEEE Transactions on Affective Computing 2022. [[paper]](https://ieeexplore.ieee.org/abstract/document/9765342)
2. Jie Zhou, Jiabao Zhao, Jimmy Xiangji Huang, Qinmin Vivian Hu, and Liang He. **MASAD: A Large-Scale Dataset for Multimodal Aspect-Based Sentiment Analysis**. Neurocomputing 2021. [[paper]](https://www.sciencedirect.com/science/article/pii/S0925231221007931)
3. Nan Xu, Wenji Mao, and Guandan Chen. **Multi-interactive Memory Network for Aspect Based Multimodal Sentiment Analysis**. AAAI 2019. [[paper]](https://ojs.aaai.org//index.php/AAAI/article/view/3807) [[code]](https://github.com/xunan0812/MIMN)



### 1.3 Multimodal Aspect-based Sentiment Classification(MABSC)
1. Hao Yang, Yanyan Zhao and Bing Qin. **Face-Sensitive Image-to-Emotional-Text Cross-modal Translation for Multimodal Aspect-based Sentiment Analysis**. EMNLP 2022 [[code]](https://github.com/yhit98/FITE)
1. Fei Zhao, Zhen Wu, Siyu Long, Xinyu Dai, Shujian Huang, Jiajun Chen. **Learning from Adjective-Noun Pairs: A Knowledge-enhanced Framework for Target-Oriented Multimodal Sentiment Classification**. COLING 2022 [[paper]](https://aclanthology.org/2022.coling-1.590.pdf)
1. Yufeng Huang, Zhuo Chen, Wen Zhang, Jiaoyan Chen, Jeff Z. Pan,Zhen Yao, Yujie Xie, Huajun Chen. **Aspect-based Sentiment Classification with Sequential Cross-modal Semantic Graph**. arxiv 2022 [[paper]](https://arxiv.org/pdf/2208.09417.pdf)
1. Yang Yu, Dong Zhang, Shoushan Li. **Unified Multi-modal Pre-training for Few-shot Sentiment Analysis with Prompt-based Learning**. ACM MM2022 [[paper]](https://dl.acm.org/doi/abs/10.1145/3503161.3548306)
3. Junjie Ye, Jie Zhou, Junfeng Tian, Rui Wang, Jingyi Zhou, Tao Gui, Qi Zhang,Xuanjing Huang. **Sentiment-aware multimodal pre-training for multimodal sentiment
analysis**. KBS 2022 [[paper]](https://www.sciencedirect.com/science/article/pii/S0950705122011145)
1. Zhen Li, Bing Xu, Conghui Zhu, and Tiejun Zhao. **CLMLF: A Contrastive Learning and Multi-Layer Fusion Method for Multimodal Sentiment Detection**. NAACL 2022 Findings. [[paper]](https://aclanthology.org/2022.findings-naacl.175.pdf)
2. Jianfei Yu, Jieming Wang, Rui Xia and Junjie Li. **Targeted Multimodal Sentiment Classification based on Coarse-to-Fine Grained Image-Target Matching**. IJCAI 2022. [[paper]](https://www.ijcai.org/proceedings/2022/0622.pdf)
3. Zaid Khan and Yun Fu. **Exploiting BERT For Multimodal Target Sentiment Classification Through Input Space Translation**. ACM MM 2021 [[paper]](https://arxiv.org/pdf/2108.01682.pdf) [[code]](https://github.com/codezakh/exploiting-BERT-thru-translation)
4. Zhe Zhang, Zhu Wang, Xiaona Li, Nannan Liu, Bin Guo, and Zhiwen Yu. **ModalNet: an aspect-level sentiment classification model by exploring multimodal data with fusion discriminant attentional network**. World Wide Web 2021. [[paper]](https://link.springer.com/article/10.1007/s11280-021-00955-7) 
5. Jianfei Yu, Jing Jiang and Rui Xia. **Entity-Sensitive Attention and Fusion Network for Entity-Level Multimodal Sentiment Classification**. IEEE/ACM TASLP 2020. [[paper]](https://ink.library.smu.edu.sg/cgi/viewcontent.cgi?article=6507&context=sis_research)
6. Jianfei Yu and Jing Jiang. **Adapting BERT for Target-Oriented Multimodal Sentiment Classification**. IJCAI 2019. [[paper]](https://www.ijcai.org/Proceedings/2019/0751.pdf) [[code]](https://github.com/jefferyYu/TomBERT)

### 1.4 Multimodal Aspect-Sentiment Pair Extraction(MASPE)
1. Ru Zhou, Wenya Guo, Xumeng Liu, Shenglong Yu, Ying Zhang, and Xiaojie Yuan. **AoM: Detecting Aspect-oriented Information for Multimodal Aspect-Based Sentiment Analysis**. Findings of ACL 2023. [[paper]](https://arxiv.org/pdf/2306.01004.pdf) [[code]](https://github.com/SilyRab/AoM)
2. Xiaocui Yang, Shi Feng, Daling Wang, Sun Qi, Wenfang Wu, Yifei Zhang, Pengfei Hong, and Soujanya Poria. **Few-shot Joint Multimodal Aspect-Sentiment Analysis Based on Generative Multimodal Prompt**. Findings of ACL 2023. [[paper]](https://arxiv.org/pdf/2305.10169.pdf) [[code]](https://github.com/YangXiaocui1215/GMP)
3. Zhewen Yu, Jin Wang, Liang-Chih Yu, and Xuejie Zhang. **Dual-Encoder Transformers with Cross-modal Alignment for Multimodal Aspect-based Sentiment Analysis**. AACL-IJCNLP 2022. [[paper]](https://aclanthology.org/2022.aacl-main.32.pdf) [[code]](https://github.com/windforfurture/DTCA)
4. Li Yang, Jin-Cheon Na, and Jianfei Yu. **Cross-Modal Multitask Transformer for End-to-End Multimodal Aspect-Based Sentiment Analysis**. Information Processing and Management, 59(5), 103038, 2022. [[paper]](https://www.sciencedirect.com/science/article/pii/S0306457322001479?via%3Dihub) [[code]](https://github.com/yangli-hub/CMMT-Code)
5. Yan Ling, Jianfei Yu, and Rui Xia. **Vision-Language Pre-Training for Multimodal Aspect-Based Sentiment Analysis**. ACL 2022. [[paper]](https://aclanthology.org/2022.acl-long.152.pdf) [[code]](https://github.com/NUSTM/VLP-MABSA)
6. Xincheng Ju,  Dong Zhang,  Rong Xiao,  Junhui Li, Shoushan Li, Min Zhang, and Guodong Zhou. **Joint Multi-Modal Aspect-Sentiment Analysis with Auxiliary Cross-Modal Relation  Detection**. EMNLP 2021 [[paper]](https://aclanthology.org/2021.emnlp-main.360.pdf) [[code]](https://github.com/MANLP-suda/JML)

### 1.5 Multimodal Aspect-Category-Sentiment Triple Extraction(MACSTE)
1. Li Yang, Jieming Wang, Jin-Cheon Na, and Jianfei Yu. **Generating Paraphrase Sentences for Multimodal Entity-Category-Sentiment Triple Extraction**. In Knowledge-Based Systems, 2023. [[paper]](https://www.sciencedirect.com/science/article/pii/S0950705123005737)
